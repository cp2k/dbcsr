<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
   
   <meta name="description" content="">
    
    <meta name="author" content="DBCSR Authors" >
    <link rel="icon" href="../favicon.png">

    <title>dbcsr_tensor &ndash; DBCSR</title>

    <link href="../css/bootstrap.min.css" rel="stylesheet">
    <link href="../css/pygments.css" rel="stylesheet">
    <link href="../css/font-awesome.min.css" rel="stylesheet">
    <link href="../css/local.css" rel="stylesheet">
    
    

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    
    <script src="../js/jquery-2.1.3.min.js"></script>
    <script src="../js/svg-pan-zoom.min.js"></script>

  </head>

  <body>

    <!-- Fixed navbar -->
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../index.html">DBCSR <small>2.1.0-90-ga221523a5</small></a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
        
            <li><a href='../page/index.html'>Guide</a></li>
      
            <li class="dropdown hidden-xs visible-sm visible-md hidden-lg">
              <a href="#" class="dropdown-toggle"
              data-toggle="dropdown" role="button"
              aria-haspopup="true"
     aria-expanded="false">Contents <span class="caret"></span></a>
        <ul class="dropdown-menu">
          
              
            <li><a href="../lists/files.html">Source Files</a></li>
        
        
        
            <li><a href="../lists/modules.html">Modules</a></li>
        
            
                                
            <li><a href="../lists/procedures.html">Procedures</a></li>
        
        
            <li><a href="../lists/absint.html">Abstract Interfaces</a></li>
               
            <li><a href="../lists/types.html">Derived Types</a></li>
        
        
            <li><a href="../lists/programs.html">Programs</a></li>
               
        
        
            </ul>
        
            </li>


<li class="visible-xs hidden-sm visible-lg"><a href="../lists/files.html">Source Files</a></li>



<li class="visible-xs hidden-sm visible-lg"><a href="../lists/modules.html">Modules</a></li>



<li class="visible-xs hidden-sm visible-lg"><a href="../lists/procedures.html">Procedures</a></li>


<li class="visible-xs hidden-sm visible-lg"><a href="../lists/absint.html">Abstract Interfaces</a></li>
                             
<li class="visible-xs hidden-sm visible-lg"><a href="../lists/types.html">Derived Types</a></li>


<li class="visible-xs hidden-sm visible-lg"><a href="../lists/programs.html">Programs</a></li>



          </ul>
        
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">
    
  
  <div class="row">
    <h1>dbcsr_tensor 
    <small>Module</small>
    
    </h1>
    
<div class="row">
  <div class="col-lg-12">
<div class="well well-sm">
  <ul class="list-inline" style="margin-bottom:0px;display:inline">
     
     
     
     
     
    
    
     <li><i class="fa fa-list-ol"></i>
       <a data-toggle="tooltip"
    data-placement="bottom" data-html="true"
    title=" 2.7% of total for modules and submodules.">1729 statements</a>
     </li> 
     
     
     
    <li><i class="fa fa-code"></i><a href="../src/dbcsr_tensor.F"> Source File</a></li>
     
     
  </ul>
  <ol class="breadcrumb in-well text-right">
  
    
     <li><a href='../sourcefile/dbcsr_tensor.f.html'>dbcsr_tensor.F</a></li>
    
  
     <li class="active">dbcsr_tensor</li>
  </ol>
</div>
</div>
</div>
<script>
  $(function () {
  $('[data-toggle="tooltip"]').tooltip()
  })
</script>

  </div>
  
  <div class="row">
    <div class="col-md-3 hidden-xs hidden-sm visible-md visible-lg">
    
<div id="sidebar">
  
<h3>Contents</h3>
 



<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title"><a data-toggle="collapse" href="#vars-0">Variables</a></h3></div>
  <div id="vars-0" class="panel-collapse collapse">
    <div class="list-group">
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#variable-modulen~14">moduleN</a>
      
    </div>
  </div>
</div>












<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title"><a data-toggle="collapse" href="#funcs-0">Functions</a></h3></div>
  <div id="funcs-0" class="panel-collapse collapse">
    <div class="list-group">
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-update_contraction_storage">update_contraction_storage</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-compat_map">compat_map</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-opt_pgrid">opt_pgrid</a>
      
    </div>
  </div>
</div>



<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title"><a data-toggle="collapse" href="#subs-0">Subroutines</a></h3></div>
  <div class="list-group">
    <div id="subs-0" class="panel-collapse collapse">
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy">dbcsr_t_copy</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy_expert">dbcsr_t_copy_expert</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy_nocomm">dbcsr_t_copy_nocomm</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy_matrix_to_tensor">dbcsr_t_copy_matrix_to_tensor</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy_tensor_to_matrix">dbcsr_t_copy_tensor_to_matrix</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_contract">dbcsr_t_contract</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_contract_expert">dbcsr_t_contract_expert</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-align_tensor">align_tensor</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-reshape_mm_compatible">reshape_mm_compatible</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-reshape_mm_small">reshape_mm_small</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-invert_transpose_flag">invert_transpose_flag</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-index_linked_sort">index_linked_sort</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_remap">dbcsr_t_remap</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_align_index">dbcsr_t_align_index</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_permute_index">dbcsr_t_permute_index</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_contract_index">dbcsr_t_contract_index</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_map_bounds_to_tensors">dbcsr_t_map_bounds_to_tensors</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_print_contraction_index">dbcsr_t_print_contraction_index</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_batched_contract_init">dbcsr_t_batched_contract_init</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_batched_contract_finalize">dbcsr_t_batched_contract_finalize</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_change_pgrid">dbcsr_t_change_pgrid</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_change_pgrid_2d">dbcsr_t_change_pgrid_2d</a>
      
    </div>
  </div>
</div>










</div>

    </div>
    
    <div class="col-md-9" id='text'>
    <p>DBCSR tensor framework for block-sparse tensor contraction.
Representation of n-rank tensors as DBCSR tall-and-skinny matrices.
Support for arbitrary redistribution between different representations.
Support for arbitrary tensor contractions
\todo implement checks and error messages</p>
      <br>
    
  
    <div class="panel panel-default">
      <div class="panel-heading">
  <h3 class="panel-title">Uses</h3>
      </div>
      <ul class="list-group">
      
      <li class="list-group-item">
  <ul class="list-inline">
    
    <li><a href='../module/dbcsr_mpiwrap.html'>dbcsr_mpiwrap</a></li>
    
    <li><a href='../module/dbcsr_data_types.html'>dbcsr_data_types</a></li>
    
    <li><a href='../module/dbcsr_tensor_reshape.html'>dbcsr_tensor_reshape</a></li>
    
    <li><a href='../module/dbcsr_tas_types.html'>dbcsr_tas_types</a></li>
    
    <li><a href='../module/dbcsr_tensor_types.html'>dbcsr_tensor_types</a></li>
    
    <li><a href='../module/dbcsr_tensor_io.html'>dbcsr_tensor_io</a></li>
    
    <li><a href='../module/dbcsr_tensor_block.html'>dbcsr_tensor_block</a></li>
    
    <li><a href='../module/dbcsr_allocate_wrap.html'>dbcsr_allocate_wrap</a></li>
    
    <li><a href='../module/dbcsr_tensor_split.html'>dbcsr_tensor_split</a></li>
    
    <li><a href='../module/dbcsr_tas_base.html'>dbcsr_tas_base</a></li>
    
    <li><a href='../module/dbcsr_tas_mm.html'>dbcsr_tas_mm</a></li>
    
    <li><a href='../module/dbcsr_tas_split.html'>dbcsr_tas_split</a></li>
    
    <li><a href='../module/dbcsr_dist_operations.html'>dbcsr_dist_operations</a></li>
    
    <li><a href='../module/dbcsr_api.html'>dbcsr_api</a></li>
    
    <li><a href='../module/dbcsr_array_list_methods.html'>dbcsr_array_list_methods</a></li>
    
    <li><a href='../module/dbcsr_kinds.html'>dbcsr_kinds</a></li>
    
    <li><a href='../module/dbcsr_tensor_index.html'>dbcsr_tensor_index</a></li>
    
    <li><a href='../module/dbcsr_toollib.html'>dbcsr_toollib</a></li>
    
    <li><a href='../module/dbcsr_base_hooks.html'>dbcsr_base_hooks</a></li>
    
  </ul>
      </li>
      
      
      
      </ul>
    </div>
    

    
    

    <br>

    <section class="visible-xs visible-sm hidden-md">
      
<h3>Contents</h3>
 



<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title"><a data-toggle="collapse" href="#vars-1">Variables</a></h3></div>
  <div id="vars-1" class="panel-collapse collapse">
    <div class="list-group">
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#variable-modulen~14">moduleN</a>
      
    </div>
  </div>
</div>












<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title"><a data-toggle="collapse" href="#funcs-1">Functions</a></h3></div>
  <div id="funcs-1" class="panel-collapse collapse">
    <div class="list-group">
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-update_contraction_storage">update_contraction_storage</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-compat_map">compat_map</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-opt_pgrid">opt_pgrid</a>
      
    </div>
  </div>
</div>



<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title"><a data-toggle="collapse" href="#subs-1">Subroutines</a></h3></div>
  <div class="list-group">
    <div id="subs-1" class="panel-collapse collapse">
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy">dbcsr_t_copy</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy_expert">dbcsr_t_copy_expert</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy_nocomm">dbcsr_t_copy_nocomm</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy_matrix_to_tensor">dbcsr_t_copy_matrix_to_tensor</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_copy_tensor_to_matrix">dbcsr_t_copy_tensor_to_matrix</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_contract">dbcsr_t_contract</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_contract_expert">dbcsr_t_contract_expert</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-align_tensor">align_tensor</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-reshape_mm_compatible">reshape_mm_compatible</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-reshape_mm_small">reshape_mm_small</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-invert_transpose_flag">invert_transpose_flag</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-index_linked_sort">index_linked_sort</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_remap">dbcsr_t_remap</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_align_index">dbcsr_t_align_index</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_permute_index">dbcsr_t_permute_index</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_contract_index">dbcsr_t_contract_index</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_map_bounds_to_tensors">dbcsr_t_map_bounds_to_tensors</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_print_contraction_index">dbcsr_t_print_contraction_index</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_batched_contract_init">dbcsr_t_batched_contract_init</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_batched_contract_finalize">dbcsr_t_batched_contract_finalize</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_change_pgrid">dbcsr_t_change_pgrid</a>
      
      <a class="list-group-item" href="../module/dbcsr_tensor.html#proc-dbcsr_t_change_pgrid_2d">dbcsr_t_change_pgrid_2d</a>
      
    </div>
  </div>
</div>










    </section>
    <br class="visible-xs visible-sm hidden-md">

    

    
    <section>
    <h2>Variables</h2>
    
<table class="table table-striped varlist">
<thead><tr><th>Type</th><th>Visibility</th>

<th>Attributes</th><th></th><th>Name</th><th></th><th>Initial</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" id="variable-modulen~14"></span>character(len=*),</td>
  
  <td>private,</td>
  <td>parameter</td><td>::</td>
  <td><strong>moduleN</strong></td><td> =</td><td>'dbcsr_tensor'</td><td></td>
  
</tr>

</tbody>
</table>

    </section>
    <br>
    
    
    
    
    

    
    
    
    
     
    <section>
    <h2>Functions</h2>
    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-update_contraction_storage"></span><h3>
private function <a href='../proc/update_contraction_storage.html'>update_contraction_storage</a>(storage, split_opt, split) result(do_change_pgrid)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>update contraction storage that keeps track of process grids during a batched contraction
and decide if tensor process grid needs to be optimized</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_contraction_storage.html'>dbcsr_t_contraction_storage</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>storage</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_tas_split_info.html'>dbcsr_tas_split_info</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>split_opt</strong></td><td><p>optimized TAS process grid</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_tas_split_info.html'>dbcsr_tas_split_info</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>split</strong></td><td><p>current TAS process grid</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  
  
  
  
     <h4>Return Value <small>logical,
  DIMENSION(2)</small></h4>
  
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-compat_map"></span><h3>
private function <a href='../proc/compat_map.html'>compat_map</a>(nd_index, compat_ind)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Check if 2d index is compatible with tensor index</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/nd_to_2d_mapping.html'>nd_to_2d_mapping</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>nd_index</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>compat_ind</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  
  
  
  
     <h4>Return Value <small>integer
  </small></h4>
  
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-opt_pgrid"></span><h3>
private function <a href='../proc/opt_pgrid.html'>opt_pgrid</a>(tensor, tas_split_info)
    
    
   
</h3></div>
  <div class="panel-body">
       
    
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_tas_split_info.html'>dbcsr_tas_split_info</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tas_split_info</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  
  
  
  
     <h4>Return Value <small>type(<a href='../type/dbcsr_t_pgrid_type.html'>dbcsr_t_pgrid_type</a>)
  </small></h4>
  
    

  </div>
  </div>

    
    </section>
    <br>
    

    
    <section>
    <h2>Subroutines</h2>
    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_copy"></span><h3>
public subroutine <a href='../proc/dbcsr_t_copy.html'>dbcsr_t_copy</a>(tensor_in, tensor_out, order, summation, bounds, move_data, unit_nr)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Copy tensor data.
Redistributes tensor data according to distributions of target and source tensor.
Permutes tensor index according to <code>order</code> argument (if present).
Source and target tensor formats are arbitrary as long as the following requirements are met:
* source and target tensors have the same rank and the same sizes in each dimension in terms
  of tensor elements (block sizes don't need to be the same).
  If <code>order</code> argument is present, sizes must match after index permutation.
OR
* target tensor is not yet created, in this case an exact copy of source tensor is returned.</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_in</strong></td><td><p>Source
Target</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_out</strong></td><td><p>Source
Target</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(ndims_tensor(tensor_in))</td><td>::</td>
  <td><strong>order</strong></td><td><p>Permutation of target tensor index. Exact same convention as order argument of RESHAPE intrinsic</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>summation</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, ndims_tensor(tensor_in))</td><td>::</td>
  <td><strong>bounds</strong></td><td><p>crop tensor data: start and end index for each tensor dimension</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>move_data</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_copy_expert"></span><h3>
private subroutine <a href='../proc/dbcsr_t_copy_expert.html'>dbcsr_t_copy_expert</a>(tensor_in, tensor_out, order, summation, bounds, move_data, unit_nr)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>expert routine for copying a tensor. For internal use only.</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(ndims_tensor(tensor_in))</td><td>::</td>
  <td><strong>order</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>summation</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, ndims_tensor(tensor_in))</td><td>::</td>
  <td><strong>bounds</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>move_data</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_copy_nocomm"></span><h3>
private subroutine <a href='../proc/dbcsr_t_copy_nocomm.html'>dbcsr_t_copy_nocomm</a>(tensor_in, tensor_out, summation)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>copy without communication, requires that both tensors have same process grid and distribution</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>summation</strong></td><td><p>Whether to sum matrices b = a + b</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_copy_matrix_to_tensor"></span><h3>
public subroutine <a href='../proc/dbcsr_t_copy_matrix_to_tensor.html'>dbcsr_t_copy_matrix_to_tensor</a>(matrix_in, tensor_out, summation)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>copy matrix to tensor.</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_type~2.html'>dbcsr_type</a>),</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>matrix_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>summation</strong></td><td><p>tensor_out = tensor_out + matrix_in</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_copy_tensor_to_matrix"></span><h3>
public subroutine <a href='../proc/dbcsr_t_copy_tensor_to_matrix.html'>dbcsr_t_copy_tensor_to_matrix</a>(tensor_in, matrix_out, summation)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>copy tensor to matrix</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_type~2.html'>dbcsr_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>matrix_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>summation</strong></td><td><p>matrix_out = matrix_out + tensor_in</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_contract"></span><h3>
public subroutine <a href='../proc/dbcsr_t_contract.html'>dbcsr_t_contract</a>(alpha, tensor_1, tensor_2, beta, tensor_3, contract_1, notcontract_1, contract_2, notcontract_2, map_1, map_2, bounds_1, bounds_2, bounds_3, optimize_dist, pgrid_opt_1, pgrid_opt_2, pgrid_opt_3, filter_eps, flop, move_data, retain_sparsity, unit_nr, log_verbose)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Contract tensors by multiplying matrix representations.
tensor_3(map_1, map_2) := alpha * tensor_1(notcontract_1, contract_1)
* tensor_2(contract_2, notcontract_2)
+ beta * tensor_3(map_1, map_2)</p><a href="../proc/dbcsr_t_contract.html" class="pull-right"><emph>Read more&hellip;</emph></a>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_scalar_type.html'>dbcsr_scalar_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>alpha</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_1</strong></td><td><p>first tensor (in)</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_2</strong></td><td><p>second tensor (in)</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_scalar_type.html'>dbcsr_scalar_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>beta</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_3</strong></td><td><p>contracted tensor (out)</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>contract_1</strong></td><td><p>indices of tensor_1 to contract</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>notcontract_1</strong></td><td><p>indices of tensor_1 not to contract</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>contract_2</strong></td><td><p>indices of tensor_2 to contract (1:1 with contract_1)</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>notcontract_2</strong></td><td><p>indices of tensor_2 not to contract</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>map_1</strong></td><td><p>which indices of tensor_3 map to non-contracted indices of tensor_1 (1:1 with notcontract_1)</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>map_2</strong></td><td><p>which indices of tensor_3 map to non-contracted indices of tensor_2 (1:1 with notcontract_2)</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(contract_1))</td><td>::</td>
  <td><strong>bounds_1</strong></td><td><p>bounds corresponding to contract_1 AKA contract_2: start and end index of an index range over
which to contract. For use in batched contraction.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(notcontract_1))</td><td>::</td>
  <td><strong>bounds_2</strong></td><td><p>bounds corresponding to notcontract_1: start and end index of an index range.
For use in batched contraction.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(notcontract_2))</td><td>::</td>
  <td><strong>bounds_3</strong></td><td><p>bounds corresponding to notcontract_2: start and end index of an index range.
For use in batched contraction.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>optimize_dist</strong></td><td><p>Whether distribution should be optimized internally. In the current implementation this guarantees optimal parameters
only for dense matrices.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_pgrid_type.html'>dbcsr_t_pgrid_type</a>),</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td>POINTER</td><td>::</td>
  <td><strong>pgrid_opt_1</strong></td><td><p>Optionally return optimal process grid for tensor_1. This can be used to choose optimal process grids for subsequent
tensor contractions with tensors of similar shape and sparsity. Under some conditions, pgrid_opt_1 can not be returned,
in this case the pointer is not associated.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_pgrid_type.html'>dbcsr_t_pgrid_type</a>),</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td>POINTER</td><td>::</td>
  <td><strong>pgrid_opt_2</strong></td><td><p>Optionally return optimal process grid for tensor_2.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_pgrid_type.html'>dbcsr_t_pgrid_type</a>),</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td>POINTER</td><td>::</td>
  <td><strong>pgrid_opt_3</strong></td><td><p>Optionally return optimal process grid for tensor_3.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>real(kind=real_8),</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>filter_eps</strong></td><td><p>As in DBCSR mm</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer(kind=int_8),</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>flop</strong></td><td><p>As in DBCSR mm</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>move_data</strong></td><td><p>memory optimization: transfer data such that tensor_1 and tensor_2 are empty on return</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>retain_sparsity</strong></td><td><p>enforce the sparsity pattern of the existing tensor_3; default is no</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td><p>output unit for logging
set it to -1 on ranks that should not write (and any valid unit number on ranks that should write output)
if 0 on ALL ranks, no output is written</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>log_verbose</strong></td><td><p>verbose logging (for testing only)</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_contract_expert"></span><h3>
private subroutine <a href='../proc/dbcsr_t_contract_expert.html'>dbcsr_t_contract_expert</a>(alpha, tensor_1, tensor_2, beta, tensor_3, contract_1, notcontract_1, contract_2, notcontract_2, map_1, map_2, bounds_1, bounds_2, bounds_3, optimize_dist, pgrid_opt_1, pgrid_opt_2, pgrid_opt_3, filter_eps, flop, move_data, retain_sparsity, nblks_local, result_index, unit_nr, log_verbose)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>expert routine for tensor contraction. For internal use only.</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_scalar_type.html'>dbcsr_scalar_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>alpha</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_scalar_type.html'>dbcsr_scalar_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>beta</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_3</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>contract_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>notcontract_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>contract_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>notcontract_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>map_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>map_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(contract_1))</td><td>::</td>
  <td><strong>bounds_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(notcontract_1))</td><td>::</td>
  <td><strong>bounds_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(notcontract_2))</td><td>::</td>
  <td><strong>bounds_3</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>optimize_dist</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_pgrid_type.html'>dbcsr_t_pgrid_type</a>),</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td>POINTER</td><td>::</td>
  <td><strong>pgrid_opt_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_pgrid_type.html'>dbcsr_t_pgrid_type</a>),</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td>POINTER</td><td>::</td>
  <td><strong>pgrid_opt_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_pgrid_type.html'>dbcsr_t_pgrid_type</a>),</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td>POINTER</td><td>::</td>
  <td><strong>pgrid_opt_3</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>real(kind=real_8),</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>filter_eps</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer(kind=int_8),</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>flop</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>move_data</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>retain_sparsity</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>nblks_local</strong></td><td><p>number of local blocks on this MPI rank</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td>DIMENSION(dbcsr_t_max_nblks_local(tensor_3), ndims_tensor(tensor_3))</td><td>::</td>
  <td><strong>result_index</strong></td><td><p>get indices of non-zero tensor blocks for tensor_3 without actually performing contraction
this is an estimate based on block norm multiplication</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>log_verbose</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-align_tensor"></span><h3>
private subroutine <a href='../proc/align_tensor.html'>align_tensor</a>(tensor_in, contract_in, notcontract_in, tensor_out, contract_out, notcontract_out, indp_in, indp_out)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>align tensor index with data</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>contract_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>notcontract_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out),</td>
  <td></td>
  
  <td>DIMENSION(SIZE(contract_in))</td><td>::</td>
  <td><strong>contract_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out),</td>
  <td></td>
  
  <td>DIMENSION(SIZE(notcontract_in))</td><td>::</td>
  <td><strong>notcontract_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=1),</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(ndims_tensor(tensor_in))</td><td>::</td>
  <td><strong>indp_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=1),</td>
  <td>intent(out),</td>
  <td></td>
  
  <td>DIMENSION(ndims_tensor(tensor_in))</td><td>::</td>
  <td><strong>indp_out</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-reshape_mm_compatible"></span><h3>
private subroutine <a href='../proc/reshape_mm_compatible.html'>reshape_mm_compatible</a>(tensor1, tensor2, tensor1_out, tensor2_out, ind1_free, ind1_linked, ind2_free, ind2_linked, trans1, trans2, new1, new2, ref_tensor, nodata1, nodata2, move_data_1, move_data_2, optimize_dist, unit_nr)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Prepare tensor for contraction: redistribute to a 2d format which can be contracted by
matrix multiplication. This routine reshapes the two largest of the three tensors. Redistribution
is avoided if tensors already in a consistent layout.</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor1</strong></td><td><p>tensor 1 in</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor2</strong></td><td><p>tensor 2 in</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(out),</td>
  <td></td>
  
  <td>POINTER</td><td>::</td>
  <td><strong>tensor1_out</strong></td><td><p>tensor 1 out
tensor 2 out</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(out),</td>
  <td></td>
  
  <td>POINTER</td><td>::</td>
  <td><strong>tensor2_out</strong></td><td><p>tensor 1 out
tensor 2 out</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>ind1_free</strong></td><td><p>indices of tensor 1 that are "free" (not linked to any index of tensor 2)</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>ind1_linked</strong></td><td><p>indices of tensor 1 that are linked to indices of tensor 2
1:1 correspondence with ind1_linked</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>ind2_free</strong></td><td><p>indices of tensor 1 that are "free" (not linked to any index of tensor 2)</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>ind2_linked</strong></td><td><p>indices of tensor 1 that are linked to indices of tensor 2
1:1 correspondence with ind1_linked</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=1),</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>trans1</strong></td><td><p>transpose flag of matrix rep. of tensor 1
transpose flag of matrix rep. tensor 2</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=1),</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>trans2</strong></td><td><p>transpose flag of matrix rep. of tensor 1
transpose flag of matrix rep. tensor 2</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>new1</strong></td><td><p>whether a new tensor 1 was created
whether a new tensor 2 was created</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>new2</strong></td><td><p>whether a new tensor 1 was created
whether a new tensor 2 was created</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>ref_tensor</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>nodata1</strong></td><td><p>don't copy data of tensor 1
don't copy data of tensor 2</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>nodata2</strong></td><td><p>don't copy data of tensor 1
don't copy data of tensor 2</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(inout),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>move_data_1</strong></td><td><p>memory optimization: transfer data s.t. tensor1 may be empty on return
memory optimization: transfer data s.t. tensor2 may be empty on return</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(inout),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>move_data_2</strong></td><td><p>memory optimization: transfer data s.t. tensor1 may be empty on return
memory optimization: transfer data s.t. tensor2 may be empty on return</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>optimize_dist</strong></td><td><p>experimental: optimize distribution</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td><p>output unit</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-reshape_mm_small"></span><h3>
private subroutine <a href='../proc/reshape_mm_small.html'>reshape_mm_small</a>(tensor_in, ind1, ind2, tensor_out, trans, new, nodata, move_data, unit_nr)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Prepare tensor for contraction: redistribute to a 2d format which can be contracted by
matrix multiplication. This routine reshapes the smallest of the three tensors.</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_in</strong></td><td><p>tensor in</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>ind1</strong></td><td><p>index that should be mapped to first matrix dimension
index that should be mapped to second matrix dimension</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>ind2</strong></td><td><p>index that should be mapped to first matrix dimension
index that should be mapped to second matrix dimension</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(out),</td>
  <td></td>
  
  <td>POINTER</td><td>::</td>
  <td><strong>tensor_out</strong></td><td><p>tensor out</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=1),</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>trans</strong></td><td><p>transpose flag of matrix rep.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>new</strong></td><td><p>whether a new tensor was created for tensor_out</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>nodata</strong></td><td><p>don't copy tensor data
memory optimization: transfer data s.t. tensor_in may be empty on return</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>move_data</strong></td><td><p>don't copy tensor data
memory optimization: transfer data s.t. tensor_in may be empty on return</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td><p>output unit</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-invert_transpose_flag"></span><h3>
private subroutine <a href='../proc/invert_transpose_flag.html'>invert_transpose_flag</a>(trans_flag)
    
    
   
</h3></div>
  <div class="panel-body">
       
    
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=1),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>trans_flag</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-index_linked_sort"></span><h3>
private subroutine <a href='../proc/index_linked_sort.html'>index_linked_sort</a>(ind_ref, ind_dep)
    
    
   
</h3></div>
  <div class="panel-body">
       
    
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>ind_ref</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>ind_dep</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_remap"></span><h3>
private subroutine <a href='../proc/dbcsr_t_remap.html'>dbcsr_t_remap</a>(tensor_in, map1_2d, map2_2d, tensor_out, comm_2d, dist1, dist2, mp_dims_1, mp_dims_2, name, nodata, move_data)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Copy tensor to tensor with modified index mapping</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>map1_2d</strong></td><td><p>new index mapping
new index mapping</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>map2_2d</strong></td><td><p>new index mapping
new index mapping</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>comm_2d</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/array_list.html'>array_list</a>),</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>dist1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/array_list.html'>array_list</a>),</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>dist2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td></td>
  <td>optional</td>
  
  <td>DIMENSION(SIZE(map1_2d))</td><td>::</td>
  <td><strong>mp_dims_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td></td>
  <td>optional</td>
  
  <td>DIMENSION(SIZE(map2_2d))</td><td>::</td>
  <td><strong>mp_dims_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=*),</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>name</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>nodata</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>move_data</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_align_index"></span><h3>
private subroutine <a href='../proc/dbcsr_t_align_index.html'>dbcsr_t_align_index</a>(tensor_in, tensor_out, order)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Align index with data</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td>DIMENSION(ndims_tensor(tensor_in))</td><td>::</td>
  <td><strong>order</strong></td><td><p>permutation resulting from alignment</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_permute_index"></span><h3>
private subroutine <a href='../proc/dbcsr_t_permute_index.html'>dbcsr_t_permute_index</a>(tensor_in, tensor_out, order)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Create new tensor by reordering index, data is copied exactly (shallow copy)</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_in</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_out</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(ndims_tensor(tensor_in))</td><td>::</td>
  <td><strong>order</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_contract_index"></span><h3>
public subroutine <a href='../proc/dbcsr_t_contract_index.html'>dbcsr_t_contract_index</a>(alpha, tensor_1, tensor_2, beta, tensor_3, contract_1, notcontract_1, contract_2, notcontract_2, map_1, map_2, bounds_1, bounds_2, bounds_3, filter_eps, nblks_local, result_index)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>get indices of non-zero tensor blocks for contraction result without actually
performing contraction.
this is an estimate based on block norm multiplication.
See documentation of dbcsr_t_contract.</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_scalar_type.html'>dbcsr_scalar_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>alpha</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_scalar_type.html'>dbcsr_scalar_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>beta</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout),</td>
  <td></td>
  
  <td>TARGET</td><td>::</td>
  <td><strong>tensor_3</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>contract_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>notcontract_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>contract_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>notcontract_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>map_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>map_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(contract_1))</td><td>::</td>
  <td><strong>bounds_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(notcontract_1))</td><td>::</td>
  <td><strong>bounds_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(notcontract_2))</td><td>::</td>
  <td><strong>bounds_3</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>real(kind=real_8),</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>filter_eps</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>nblks_local</strong></td><td><p>number of local blocks on this MPI rank</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out),</td>
  <td></td>
  
  <td>DIMENSION(dbcsr_t_max_nblks_local(tensor_3), ndims_tensor(tensor_3))</td><td>::</td>
  <td><strong>result_index</strong></td><td><p>indices of local non-zero tensor blocks for tensor_3
only the elements result_index(:nblks_local, :) are relevant (all others are set to 0)</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_map_bounds_to_tensors"></span><h3>
private subroutine <a href='../proc/dbcsr_t_map_bounds_to_tensors.html'>dbcsr_t_map_bounds_to_tensors</a>(tensor_1, tensor_2, contract_1, notcontract_1, contract_2, notcontract_2, bounds_t1, bounds_t2, bounds_1, bounds_2, bounds_3, do_crop_1, do_crop_2)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Map contraction bounds to bounds referring to tensor indices
see dbcsr_t_contract for docu of dummy arguments</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>contract_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>notcontract_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>contract_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>notcontract_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out),</td>
  <td></td>
  
  <td>DIMENSION(2, ndims_tensor(tensor_1))</td><td>::</td>
  <td><strong>bounds_t1</strong></td><td><p>bounds mapped to tensor_1</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(out),</td>
  <td></td>
  
  <td>DIMENSION(2, ndims_tensor(tensor_2))</td><td>::</td>
  <td><strong>bounds_t2</strong></td><td><p>bounds mapped to tensor_2</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(contract_1))</td><td>::</td>
  <td><strong>bounds_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(notcontract_1))</td><td>::</td>
  <td><strong>bounds_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2, SIZE(notcontract_2))</td><td>::</td>
  <td><strong>bounds_3</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>do_crop_1</strong></td><td><p>whether tensor 1 should be cropped
whether tensor 2 should be cropped</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>do_crop_2</strong></td><td><p>whether tensor 1 should be cropped
whether tensor 2 should be cropped</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_print_contraction_index"></span><h3>
private subroutine <a href='../proc/dbcsr_t_print_contraction_index.html'>dbcsr_t_print_contraction_index</a>(tensor_1, indchar1, tensor_2, indchar2, tensor_3, indchar3, unit_nr)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>print tensor contraction indices in a human readable way</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_1</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=1),</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(ndims_tensor(tensor_1))</td><td>::</td>
  <td><strong>indchar1</strong></td><td><p>characters printed for index of tensor 1</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_2</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=1),</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(ndims_tensor(tensor_2))</td><td>::</td>
  <td><strong>indchar2</strong></td><td><p>characters printed for index of tensor 2</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor_3</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>character(len=1),</td>
  <td>intent(in),</td>
  <td></td>
  
  <td>DIMENSION(ndims_tensor(tensor_3))</td><td>::</td>
  <td><strong>indchar3</strong></td><td><p>characters printed for index of tensor 3</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td><p>output unit</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_batched_contract_init"></span><h3>
public subroutine <a href='../proc/dbcsr_t_batched_contract_init.html'>dbcsr_t_batched_contract_init</a>(tensor, batch_range_1, batch_range_2, batch_range_3, batch_range_4)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>Initialize batched contraction for this tensor.</p><a href="../proc/dbcsr_t_batched_contract_init.html" class="pull-right"><emph>Read more&hellip;</emph></a>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>batch_range_1</strong></td><td><p>For internal load balancing optimizations, optionally specify the index ranges of
batched contraction.
batch_range_i refers to the ith tensor dimension and contains all block indices starting
a new range. The size should be the number of ranges plus one, the last element being the
block index plus one of the last block in the last range.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>batch_range_2</strong></td><td><p>For internal load balancing optimizations, optionally specify the index ranges of
batched contraction.
batch_range_i refers to the ith tensor dimension and contains all block indices starting
a new range. The size should be the number of ranges plus one, the last element being the
block index plus one of the last block in the last range.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>batch_range_3</strong></td><td><p>For internal load balancing optimizations, optionally specify the index ranges of
batched contraction.
batch_range_i refers to the ith tensor dimension and contains all block indices starting
a new range. The size should be the number of ranges plus one, the last element being the
block index plus one of the last block in the last range.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>batch_range_4</strong></td><td><p>For internal load balancing optimizations, optionally specify the index ranges of
batched contraction.
batch_range_i refers to the ith tensor dimension and contains all block indices starting
a new range. The size should be the number of ranges plus one, the last element being the
block index plus one of the last block in the last range.</p></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_batched_contract_finalize"></span><h3>
public subroutine <a href='../proc/dbcsr_t_batched_contract_finalize.html'>dbcsr_t_batched_contract_finalize</a>(tensor, unit_nr)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>finalize batched contraction. This performs all communication that has been postponed in the
contraction calls.</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_change_pgrid"></span><h3>
private subroutine <a href='../proc/dbcsr_t_change_pgrid.html'>dbcsr_t_change_pgrid</a>(tensor, pgrid, batch_range_1, batch_range_2, batch_range_3, batch_range_4, nodata, pgrid_changed, unit_nr)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>change the process grid of a tensor</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_pgrid_type.html'>dbcsr_t_pgrid_type</a>),</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>pgrid</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>batch_range_1</strong></td><td><p>For internal load balancing optimizations, optionally specify the index ranges of
batched contraction.
batch_range_i refers to the ith tensor dimension and contains all block indices starting
a new range. The size should be the number of ranges plus one, the last element being the
block index plus one of the last block in the last range.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>batch_range_2</strong></td><td><p>For internal load balancing optimizations, optionally specify the index ranges of
batched contraction.
batch_range_i refers to the ith tensor dimension and contains all block indices starting
a new range. The size should be the number of ranges plus one, the last element being the
block index plus one of the last block in the last range.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>batch_range_3</strong></td><td><p>For internal load balancing optimizations, optionally specify the index ranges of
batched contraction.
batch_range_i refers to the ith tensor dimension and contains all block indices starting
a new range. The size should be the number of ranges plus one, the last element being the
block index plus one of the last block in the last range.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(:)</td><td>::</td>
  <td><strong>batch_range_4</strong></td><td><p>For internal load balancing optimizations, optionally specify the index ranges of
batched contraction.
batch_range_i refers to the ith tensor dimension and contains all block indices starting
a new range. The size should be the number of ranges plus one, the last element being the
block index plus one of the last block in the last range.</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>nodata</strong></td><td><p>optionally don't copy the tensor data (then tensor is empty on returned)</p></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>pgrid_changed</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    
  <div class="panel panel-default">
  <div class="panel-heading codesum"><span class="anchor" id="proc-dbcsr_t_change_pgrid_2d"></span><h3>
private subroutine <a href='../proc/dbcsr_t_change_pgrid_2d.html'>dbcsr_t_change_pgrid_2d</a>(tensor, mp_comm, pdims, nodata, nsplit, dimsplit, pgrid_changed, unit_nr)
    
    
   
</h3></div>
  <div class="panel-body">
       
    







<p>map tensor to a new 2d process grid for the matrix representation.</p>
    
    <h4>Arguments</h4>
    
      
      
<table class="table table-striped varlist">
<thead><tr><th>Type</th>
<th>Intent</th><th>Optional</th>
<th>Attributes</th><th></th><th>Name</th><th></th></thead>



<tbody>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>type(<a href='../type/dbcsr_t_type.html'>dbcsr_t_type</a>),</td>
  <td>intent(inout)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>tensor</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in)</td>
  <td></td>
  
  <td></td><td>::</td>
  <td><strong>mp_comm</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td>DIMENSION(2)</td><td>::</td>
  <td><strong>pdims</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>nodata</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>nsplit</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>dimsplit</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>logical,</td>
  <td>intent(out),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>pgrid_changed</strong></td><td></td>
  
</tr>

  
  
  
  
<tr>
  
  <td><span class="anchor" ></span>integer,</td>
  <td>intent(in),</td>
  <td>optional</td>
  
  <td></td><td>::</td>
  <td><strong>unit_nr</strong></td><td></td>
  
</tr>

</tbody>
</table>

      
    
    

  </div>
  </div>

    
    </section>    
    <br>
    
    
    
    </div>
  </div>

  
    <hr>    
    </div> <!-- /container -->
    <footer>
      <div class="container">
      <div class="row">
        <div class="col-xs-6 col-md-6"><p>DBCSR was developed by DBCSR Authors<br>&copy; 2021 
                                          </p>
        </div>
        <div class="col-xs-6 col-md-6">
          <p class="text-right">
            Documentation generated by 
            <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            
            
          </p>
        </div>
      </div>
      <br>
      </div> <!-- /container -->    
    </footer>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
<!--
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
-->
    <script src="../js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../js/ie10-viewport-bug-workaround.js"></script>

    <!-- MathJax JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
        jax: ['input/TeX','input/MathML','output/HTML-CSS'],
        extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
      });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    
    
  </body>
</html>