<!-- -*- mode: jinja2 -*- -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="">
    <meta name="author" content="DBCSR Authors" >
    <link rel="icon" href="../../../../../favicon.png">

    <title>Autotuning Framework &ndash; DBCSR</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link href="../../../../../css/pygments.css" rel="stylesheet">
    <link href="../../../../../css/font-awesome.min.css" rel="stylesheet">
    <link href="../../../../../css/local.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
    <script src="../../../../../js/svg-pan-zoom.min.js"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../../../../../index.html">DBCSR <small>2.7.0-rc1</small></a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="../../../../index.html">Guide</a></li>
                  <li class="nav-item">
                    <a class="nav-link" href="../../../../../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../../../../../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../../../../../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../../../../../lists/absint.html">Abstract Interfaces</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../../../../../lists/types.html">Derived Types</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../../../../../lists/programs.html">Programs</a>
                </li>
            </ul>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>Autotuning Framework</h1>
    <div class="container p-2 mb-4 bg-light border rounded-3">
      <div class="row align-items-center justify-content-between">
        <div class="col">
          <ul class="list-inline" style="margin-bottom:0px; display:inline">
          </ul>
        </div>
        <div class="col">
          <nav aria-label="breadcrumb">
            <ol class="breadcrumb justify-content-end mb-0">
                <li class="breadcrumb-item"><a href='../../../../index.html'>Guide</a></li>
                <li class="breadcrumb-item"><a href='../../../index.html'>Developer Guide</a></li>
                <li class="breadcrumb-item"><a href='../../index.html'>Programming</a></li>
                <li class="breadcrumb-item"><a href='../index.html'>Accelerator Backend</a></li>
                <li class="breadcrumb-item"><a href='index.html'>CUDA/HIP</a></li>
              <li class="breadcrumb-item active" aria-current="page">Autotuning Framework</li>
            </ol>
          </nav>
        </div>
      </div>
    </div>
  </div>

  <div class="row">
      <div class="col-3">
        <div class="card card-body bg-light" id="sidebar-toc">
          <ul class="nav flex-column align-items">
            <li class="nav-item">
              <a class="nav-link" href="../../../../index.html">Guide</a>
            </li>
          </ul>
          <hr>
          <nav class="nav nav-pills flex-column">
              <a class="nav-link" href="../../../../1-DBCSR/index.html">DBCSR</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../../../../1-DBCSR/publications.html">Publications</a>

                </nav>
              <a class="nav-link" href="../../../../2-user-guide/index.html">User Guide</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../../../../2-user-guide/1-installation/index.html">Install</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../../../../2-user-guide/1-installation/1-cmake-build-recipes.html">CMake Build Recipes</a>
              <a class="nav-link" href="../../../../2-user-guide/1-installation/2-supported-compilers.html">Supported Compilers</a>
              <a class="nav-link" href="../../../../2-user-guide/1-installation/3-using-dbcsr-in-a-cmake-project.html">Using DBCSR in a CMake project</a>
              <a class="nav-link" href="../../../../2-user-guide/1-installation/4-docker.html">Docker Images</a>

                </nav>
              <a class="nav-link" href="../../../../2-user-guide/2-tests/index.html">Tests</a>
              <a class="nav-link" href="../../../../2-user-guide/3-examples/index.html">Examples</a>
              <a class="nav-link" href="../../../../2-user-guide/4-gpu/index.html">GPUs</a>

                </nav>
              <a class="nav-link" href="../../../index.html">Developer Guide</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../../../1-tooling/index.html">Tooling</a>
              <a class="nav-link" href="../../../2-documentation/index.html">Documentation</a>
              <a class="nav-link" href="../../index.html">Programming</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../../1-overview/index.html">Overview</a>
              <a class="nav-link" href="../index.html">Accelerator Backend</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../1-code-structure.html">Code Structure</a>
              <a class="nav-link" href="index.html">CUDA/HIP</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="1-kernels.html">Kernels</a>
              <a class="nav-link" href="2-parameters.html">Kernel Parameters</a>
              <a class="nav-link active disabled" href="3-tune.html">Autotuning Framework</a>
              <a class="nav-link" href="4-predict.html">Predictive Modeling Framework</a>
              <a class="nav-link" href="5-notebooks.html">Notebooks</a>

                </nav>
              <a class="nav-link" href="../3-libsmm_ocl/index.html">OpenCL</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../3-libsmm_ocl/1-autotune.html">Autotune</a>
              <a class="nav-link" href="../3-libsmm_ocl/2-bulktune.html">Parameters</a>

                </nav>

                </nav>

                </nav>
              <a class="nav-link" href="../../../4-performance/index.html">Performance</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../../../4-performance/1-insights.html">Insights</a>
              <a class="nav-link" href="../../../4-performance/2-just-in-time-compilation.html">JIT</a>

                </nav>

                </nav>
          </nav>
        </div>
      </div>

    <div class="col-9" id='text'>
      <h1>Auto-tuning Procedure for Finding Optimal CUDA/HIP Kernel Parameters in <code>libsmm_acc</code></h1>
<p>The performance of the matrix-matrix multiplication kernels is highly dependent on the choice of algorithm and parameters. This is why auto-tuning is used to find optimal kernel parameters.</p>
<hr>
<h3>Requirements</h3>
<p>Python version required: <code>python 3.6+</code></p>
<p>If you are about to autotune parameters for a new GPU (i.e. a GPU for which there are no auto-tuned parameters yet), please first follow <a href="https://github.com/cp2k/dbcsr/blob/develop/src/acc/libsmm_acc/README.md#adding-support-for-a-new-gpu-card">the instructions for a new GPU</a>.</p>
<p>Install all python packages required (if you do not want this project's requirements to interfere with your other Python projects, consider doing so in a <a href="https://docs.python.org/3/tutorial/venv.html">virtual environment</a>), using</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</code></pre></div>

<hr>
<h3>Auto-tuning procedure</h3>
<h4>1. Go to the <code>libsmm_acc/tune</code> directory</h4>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>dbcsr/src/acc/libsmm_acc/tune
</code></pre></div>

<p>The <code>parameters.h</code> file (a C++ header file generated from the JSON record of multiplication kernels and their optimal parameters) is needed for the auto-tuning procedure. One can copy it over from a build directory for example, as follows:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>cp<span class="w"> </span>~/dbcsr/build_dir/src/acc/libsmm_acc/parameters.h<span class="w"> </span>../
</code></pre></div>

<h4>2. Adapt <code>tune_setup.py</code> to your environment</h4>
<p>The <code>tune_setup.py</code> script generates job files. You have to adapt the script to the environment of your supercomputer and your personal settings.</p>
<div class="codehilite"><pre><span></span><code><span class="o">...</span>
<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">gen_jobfile</span><span class="p">(</span><span class="n">outdir</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="p">):</span>

<span class="w">    </span><span class="o">...</span>

<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;#!/bin/bash -l</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;#SBATCH --nodes=</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">num_nodes</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;#SBATCH --ntasks-per-core=1</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;#SBATCH --ntasks-per-node=1</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;#SBATCH --cpus-per-task=&quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">cpus_per_node</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;#SBATCH --time=</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">time</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;#SBATCH --partition=normal</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;#SBATCH --constraint=gpu</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;source ${MODULESHOME}/init/sh;</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;module load daint-gpu</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;module unload PrgEnv-cray</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;module load PrgEnv-gnu</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">compiler</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;nvcc&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;module load cudatoolkit/8.0.61_2.4.9-6.0.7.0_17.1__g899857c</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="k">else</span><span class="p">:</span><span class="w"> </span><span class="c1"># i.e. compiler = hipcc</span>
<span class="w">        </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;module load hip</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;module list</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;export CRAY_CUDA_MPS=1</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;cd $SLURM_SUBMIT_DIR </span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="n">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="s2">&quot;date</span><span class="se">\n</span><span class="s2">&quot;</span>

<span class="w">    </span><span class="o">...</span>

<span class="o">...</span>
</code></pre></div>

<h4>3. Run the script <code>tune_setup.py</code></h4>
<h5>Script arguments</h5>
<p>Specify which GPU you are auto-tuning for by passing the appropriate <code>parameters_GPU.json</code> file as an argument with <code>-p/--params</code>.</p>
<p>Specify which compiler to use for compiling kernel code by passing <code>nvcc</code> or <code>hipcc</code> as an argument with <code>-b/--compiler</code>.</p>
<p>More arguments can be set, run</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>./tune_setup.py<span class="w"> </span>--help
</code></pre></div>

<p>for more information.</p>
<h5>Script positional arguments (block sizes to autotune)</h5>
<p>In addition, the script takes as arguments the block sizes you want to add to <code>libsmm_acc</code>. You can specify these as a list of integers or provide the parameter file of a different GPU from which to read the block sizes to autotune.</p>
<h5>Examples</h5>
<p>For example, if the system you want to autotune for contains blocks of size 5 and 8, run:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>./tune_setup.py<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="m">8</span><span class="w"> </span>-p<span class="w"> </span>../parameters/parameters_P100.json
Reading<span class="w"> </span>parameters<span class="w"> </span>from<span class="w"> </span>parameters_P100.json
libsmm_acc:<span class="w"> </span>Found<span class="w"> </span><span class="m">74096</span><span class="w"> </span>existing<span class="w"> </span>parameter<span class="w"> </span>sets,<span class="w"> </span>of<span class="w"> </span>which<span class="w"> </span><span class="m">1641</span><span class="w"> </span>are<span class="w"> </span>autotuned<span class="w"> </span>and<span class="w"> </span><span class="m">72455</span><span class="w"> </span>are<span class="w"> </span>predicted.
Requested<span class="w"> </span>to<span class="w"> </span>autotune<span class="w"> </span><span class="m">8</span><span class="w"> </span>triplets
Found<span class="w"> </span><span class="m">41824</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>5x5x5
Found<span class="w"> </span><span class="m">83648</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>5x5x8
Found<span class="w"> </span><span class="m">103072</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>5x8x5
Found<span class="w"> </span><span class="m">103072</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>5x8x8
Found<span class="w"> </span><span class="m">103072</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>8x5x5
Found<span class="w"> </span><span class="m">103072</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>8x5x8
Found<span class="w"> </span><span class="m">125344</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>8x8x5
Found<span class="w"> </span><span class="m">125344</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>8x8x8
</code></pre></div>

<p>Or, if you want to obtain, for the NVIDIA P100, the parameters of the same block sizes as recorded for the NVIDIA K40, run:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>./tune_setup.py<span class="w"> </span>-p<span class="w"> </span>../parameters/parameters_P100.json<span class="w"> </span>../parameters/parameters_K40.json
Reading<span class="w"> </span>parameters<span class="w"> </span>from<span class="w"> </span>parameters_P100.json
libsmm_acc:<span class="w"> </span>Found<span class="w"> </span><span class="m">74093</span><span class="w"> </span>existing<span class="w"> </span>parameter<span class="w"> </span>sets,<span class="w"> </span>of<span class="w"> </span>which<span class="w"> </span><span class="m">1638</span><span class="w"> </span>are<span class="w"> </span>autotuned<span class="w"> </span>and<span class="w"> </span><span class="m">72455</span><span class="w"> </span>are<span class="w"> </span>predicted.
Reading<span class="w"> </span>parameters<span class="w"> </span>to<span class="w"> </span>autotune<span class="w"> </span>from<span class="w"> </span>parameters_K40.json
Requested<span class="w"> </span>to<span class="w"> </span>autotune<span class="w"> </span><span class="m">19</span><span class="w"> </span>triplets
Found<span class="w"> </span><span class="m">41824</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>5x5x5
Found<span class="w"> </span><span class="m">95648</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>6x6x6
Found<span class="w"> </span><span class="m">110496</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>7x7x7
Found<span class="w"> </span><span class="m">125344</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>8x8x8
Found<span class="w"> </span><span class="m">173764</span><span class="w"> </span>parameter<span class="w"> </span>sets<span class="w"> </span><span class="k">for</span><span class="w"> </span>9x9x9
...
</code></pre></div>

<h5>Output</h5>
<p>The script will create a directory for each combination of the block sizes:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>ls<span class="w"> </span>-d<span class="w"> </span>tune_*
tune_5x5x5<span class="w">  </span>tune_5x5x8<span class="w">  </span>tune_5x8x5<span class="w">  </span>tune_5x8x8<span class="w">  </span>tune_8x5x5<span class="w">  </span>tune_8x5x8<span class="w">  </span>tune_8x8x5<span class="w">  </span>tune_8x8x8
</code></pre></div>

<p>Each directory contains a number of files:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>ls<span class="w"> </span>-1<span class="w"> </span>tune_8x8x8/
Makefile
tune_8x8x8_exe0_main.cu/cpp
tune_8x8x8_exe0_part0.cu/cpp
tune_8x8x8_exe0_part1.cu/cpp
tune_8x8x8_exe0_part2.cu/cpp
tune_8x8x8_exe0_part3.cu/cpp
tune_8x8x8_exe0_part4.cu/cpp
tune_8x8x8.job
</code></pre></div>

<p>For each possible parameter-set a <em>launcher</em> is generated. A launcher is a small snippet of C code, which launches the kernel by using the CUDA specific <code>&lt;&lt;&lt; &gt;&gt;&gt;</code>-notation or HIP's <code>hipLaunchKernelGGL</code> function. It also instantiates the C++ template which contains the actual kernel code.</p>
<p>In order to parallelize the benchmarking, the launchers are distributed over multiple executables. Currently, up to 10'000 launchers are benchmarked by one <em>executable</em>. Each executable is linked together from several <code>tune_*_part???.o</code> and a <code>tune_*_main.o</code>. Each part-files contains up to 100 launchers. This allows to parallelize the compilation over multiple CPU cores.</p>
<h4>4. Adapt <code>tune_submit.py</code> to your environment</h4>
<p>The script <code>tune_submit.py</code> was written for the slurm batch system as used e.g. by CRAY supercomputers. If your computer runs a different batch system, you have to adapt <code>tune_submit.py</code> accordingly.</p>
<h4>5. Submit Jobs</h4>
<p>Each tune-directory contains a job file. Since there might be many tune-directories, the convenience script <code>tune_submit.py</code> can be used to submit jobs. It will go through all the <code>tune_*</code>-directories and check if its job has already been submitted or run. For this, the script calls <code>squeue</code> in the background and it searches for <code>slurm-*.out</code>files. In order to limit the number of jobs submitted at a time, a maximum number of jobs to submit can be specified with <code>-j</code>.</p>
<p>When <code>tune_submit.py</code> is called without arguments, it will just list the jobs that could be submitted:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>./tune_submit.py
<span class="w">          </span>tune_5x5x5:<span class="w"> </span>Would<span class="w"> </span>submit,<span class="w"> </span>run<span class="w"> </span>with<span class="w"> </span><span class="s2">&quot;doit!&quot;</span>
<span class="w">          </span>tune_5x5x8:<span class="w"> </span>Would<span class="w"> </span>submit,<span class="w"> </span>run<span class="w"> </span>with<span class="w"> </span><span class="s2">&quot;doit!&quot;</span>
<span class="w">          </span>tune_5x8x5:<span class="w"> </span>Would<span class="w"> </span>submit,<span class="w"> </span>run<span class="w"> </span>with<span class="w"> </span><span class="s2">&quot;doit!&quot;</span>
<span class="w">          </span>tune_5x8x8:<span class="w"> </span>Would<span class="w"> </span>submit,<span class="w"> </span>run<span class="w"> </span>with<span class="w"> </span><span class="s2">&quot;doit!&quot;</span>
<span class="w">          </span>tune_8x5x5:<span class="w"> </span>Would<span class="w"> </span>submit,<span class="w"> </span>run<span class="w"> </span>with<span class="w"> </span><span class="s2">&quot;doit!&quot;</span>
<span class="w">          </span>tune_8x5x8:<span class="w"> </span>Would<span class="w"> </span>submit,<span class="w"> </span>run<span class="w"> </span>with<span class="w"> </span><span class="s2">&quot;doit!&quot;</span>
<span class="w">          </span>tune_8x8x5:<span class="w"> </span>Would<span class="w"> </span>submit,<span class="w"> </span>run<span class="w"> </span>with<span class="w"> </span><span class="s2">&quot;doit!&quot;</span>
<span class="w">          </span>tune_8x8x8:<span class="w"> </span>Would<span class="w"> </span>submit,<span class="w"> </span>run<span class="w"> </span>with<span class="w"> </span><span class="s2">&quot;doit!&quot;</span>
Number<span class="w"> </span>of<span class="w"> </span><span class="nb">jobs</span><span class="w"> </span>submitted:<span class="w"> </span><span class="m">8</span>
</code></pre></div>

<p>Only when <code>tune_submit.py</code> is called with <code>doit!</code> as its first argument, will it actually submit jobs:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>./tune_submit.py<span class="w"> </span>doit!
<span class="w">          </span>tune_5x5x5:<span class="w"> </span>Submitting
Submitted<span class="w"> </span>batch<span class="w"> </span>job<span class="w"> </span><span class="m">277987</span>
<span class="w">          </span>tune_5x5x8:<span class="w"> </span>Submitting
Submitted<span class="w"> </span>batch<span class="w"> </span>job<span class="w"> </span><span class="m">277988</span>
<span class="w">          </span>tune_5x8x5:<span class="w"> </span>Submitting
Submitted<span class="w"> </span>batch<span class="w"> </span>job<span class="w"> </span><span class="m">277989</span>
<span class="w">          </span>tune_5x8x8:<span class="w"> </span>Submitting
Submitted<span class="w"> </span>batch<span class="w"> </span>job<span class="w"> </span><span class="m">277990</span>
<span class="w">          </span>tune_8x5x5:<span class="w"> </span>Submitting
Submitted<span class="w"> </span>batch<span class="w"> </span>job<span class="w"> </span><span class="m">277991</span>
<span class="w">          </span>tune_8x5x8:<span class="w"> </span>Submitting
Submitted<span class="w"> </span>batch<span class="w"> </span>job<span class="w"> </span><span class="m">277992</span>
<span class="w">          </span>tune_8x8x5:<span class="w"> </span>Submitting
Submitted<span class="w"> </span>batch<span class="w"> </span>job<span class="w"> </span><span class="m">277993</span>
<span class="w">          </span>tune_8x8x8:<span class="w"> </span>Submitting
Submitted<span class="w"> </span>batch<span class="w"> </span>job<span class="w"> </span><span class="m">277994</span>
Number<span class="w"> </span>of<span class="w"> </span><span class="nb">jobs</span><span class="w"> </span>submitted:<span class="w"> </span><span class="m">8</span>
</code></pre></div>

<h4>6. Collect Results</h4>
<p>Run <code>tune_collect.py</code> to parse all log files and determine the best kernel for each blocksize:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>./tune_collect.py
Reading:<span class="w"> </span>tune_5x5x5/tune_5x5x5_exe0.log
Reading:<span class="w"> </span>tune_5x5x8/tune_5x5x8_exe0.log
Reading:<span class="w"> </span>tune_5x8x5/tune_5x8x5_exe0.log
Reading:<span class="w"> </span>tune_5x8x8/tune_5x8x8_exe0.log
Reading:<span class="w"> </span>tune_8x5x5/tune_8x5x5_exe0.log
Reading:<span class="w"> </span>tune_8x5x8/tune_8x5x8_exe0.log
Reading:<span class="w"> </span>tune_8x8x5/tune_8x8x5_exe0.log
Reading:<span class="w"> </span>tune_8x8x8/tune_8x8x8_exe0.log
Kernel_dnt_tiny<span class="o">(</span><span class="nv">m</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">k</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">split_thread</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">threads</span><span class="o">=</span><span class="m">64</span>,<span class="w"> </span><span class="nv">grouping</span><span class="o">=</span><span class="m">16</span>,<span class="w"> </span><span class="nv">minblocks</span><span class="o">=</span><span class="m">1</span><span class="o">)</span><span class="w"> </span>,<span class="w"> </span><span class="c1"># 27.9623 GFlops</span>
Kernel_dnt_tiny<span class="o">(</span><span class="nv">m</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">k</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">split_thread</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">threads</span><span class="o">=</span><span class="m">96</span>,<span class="w"> </span><span class="nv">grouping</span><span class="o">=</span><span class="m">16</span>,<span class="w"> </span><span class="nv">minblocks</span><span class="o">=</span><span class="m">1</span><span class="o">)</span><span class="w"> </span>,<span class="w"> </span><span class="c1"># 37.8978 GFlops</span>
Kernel_dnt_medium<span class="o">(</span><span class="nv">m</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">k</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">tile_m</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">tile_n</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">threads</span><span class="o">=</span><span class="m">96</span>,<span class="w"> </span><span class="nv">grouping</span><span class="o">=</span><span class="m">16</span>,<span class="w"> </span><span class="nv">minblocks</span><span class="o">=</span><span class="m">8</span><span class="o">)</span><span class="w"> </span>,<span class="w"> </span><span class="c1"># 32.9231 GFlops</span>
Kernel_dnt_tiny<span class="o">(</span><span class="nv">m</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">k</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">split_thread</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">threads</span><span class="o">=</span><span class="m">96</span>,<span class="w"> </span><span class="nv">grouping</span><span class="o">=</span><span class="m">16</span>,<span class="w"> </span><span class="nv">minblocks</span><span class="o">=</span><span class="m">1</span><span class="o">)</span><span class="w"> </span>,<span class="w"> </span><span class="c1"># 47.0366 GFlops</span>
Kernel_dnt_medium<span class="o">(</span><span class="nv">m</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">k</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">tile_m</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">tile_n</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">threads</span><span class="o">=</span><span class="m">96</span>,<span class="w"> </span><span class="nv">grouping</span><span class="o">=</span><span class="m">16</span>,<span class="w"> </span><span class="nv">minblocks</span><span class="o">=</span><span class="m">12</span><span class="o">)</span><span class="w"> </span>,<span class="w"> </span><span class="c1"># 33.1999 GFlops</span>
Kernel_dnt_medium<span class="o">(</span><span class="nv">m</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">k</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">tile_m</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">tile_n</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">threads</span><span class="o">=</span><span class="m">96</span>,<span class="w"> </span><span class="nv">grouping</span><span class="o">=</span><span class="m">16</span>,<span class="w"> </span><span class="nv">minblocks</span><span class="o">=</span><span class="m">12</span><span class="o">)</span><span class="w"> </span>,<span class="w"> </span><span class="c1"># 49.3499 GFlops</span>
Kernel_dnt_tiny<span class="o">(</span><span class="nv">m</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">k</span><span class="o">=</span><span class="m">5</span>,<span class="w"> </span><span class="nv">split_thread</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">threads</span><span class="o">=</span><span class="m">96</span>,<span class="w"> </span><span class="nv">grouping</span><span class="o">=</span><span class="m">16</span>,<span class="w"> </span><span class="nv">minblocks</span><span class="o">=</span><span class="m">1</span><span class="o">)</span><span class="w"> </span>,<span class="w"> </span><span class="c1"># 62.8469 GFlops</span>
Kernel_dnt_tiny<span class="o">(</span><span class="nv">m</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">n</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">k</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">split_thread</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">threads</span><span class="o">=</span><span class="m">128</span>,<span class="w"> </span><span class="nv">grouping</span><span class="o">=</span><span class="m">16</span>,<span class="w"> </span><span class="nv">minblocks</span><span class="o">=</span><span class="m">1</span><span class="o">)</span><span class="w"> </span>,<span class="w"> </span><span class="c1"># 90.7763 GFlops</span>

Wrote<span class="w"> </span>parameters.json
</code></pre></div>

<p>The file <code>parameters.json</code> in <code>dbcsr/src/acc/libsmm_acc/parameters</code> now contains the newly autotuned parameters.</p>
<h4>7. Merge new parameters with original parameter-file</h4>
<p>Run <code>tune_merge.py</code> to merge the new parameters with the original ones, within the directory <code>parameters</code>.</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>./tune_merge.py
Merging<span class="w"> </span>parameters.json<span class="w"> </span>with<span class="w"> </span>parameters_P100.json
Wrote<span class="w"> </span>parameters.new.json
</code></pre></div>

<p>The file <code>parameters.new.json</code> can now be used as a parameter file. Rename it to <code>parameters_GPU.json</code>, with the appropriate <code>GPU</code>.</p>
<h4>8. (optional) Explore the data</h4>
<p>Explore the data interactively using the <a href="https://github.com/cp2k/dbcsr/blob/develop/src/acc/libsmm_acc/notebooks/inspect_training_data.ipynb">provided Jupyter Notebook</a>.</p>
<h4>9. Contribute parameters to the community</h4>
<p><strong>Contribute new optimal parameters</strong></p>
<p>Submit a pull request updating the appropriate <code>parameters_GPU.json</code> file to the <a href="https://github.com/cp2k/dbcsr">DBCSR repository</a>.</p>
<p><strong>Contribute autotuning data</strong></p>
<p>See <a href="https://github.com/cp2k/dbcsr-data#contributing">instructions</a> in DBCSR's <a href="https://github.com/cp2k/dbcsr-data">data repository</a>.</p>
    </div>
  </div>
      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col">
            <p>
              DBCSR
 was developed by DBCSR Authors<br>              &copy; 2024 
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>    

    <!-- MathJax JavaScript
             ================================================== -->
             <!-- Placed at the end of the document so the pages load faster -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
          jax: ['input/TeX','input/MathML','output/HTML-CSS'],
          extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
          });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  </body>
</html>